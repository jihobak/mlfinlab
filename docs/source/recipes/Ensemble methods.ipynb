{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In data science world, _Bootstrap aggregation(bagging)_ is a one of wonderful skills to get a better performance within the limited data. The advantage of using Bagging lays in its ability to reduce forecast variance and thus prevents overfitting. However, we know that financial observations cannot be simply assumed to be IID. If we don't address that issue carefully, we can not fully take advantage of the benefits of the bagging. Through mlfinlab package, We can navigate the bagging process in finance by leveraging [sklearn](https://scikit-learn.org)'s `BaggingClassifier/Regressor` with [seq_bootstrap](https://mlfinlab.readthedocs.io/en/latest/implementations/sampling.html#mlfinlab.sampling.bootstrapping.seq_bootstrap).\n",
    "\n",
    "\n",
    "Let's check how we can use _random forest_ algorithm and _sequential bootstrap_ in the _mlfinlab_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
     ]
    }
   ],
   "source": [
    "import mlfinlab as ml\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>cum_vol</th>\n",
       "      <th>cum_dollar</th>\n",
       "      <th>cum_ticks</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-04 01:17:36.863</th>\n",
       "      <td>2036.50</td>\n",
       "      <td>2043.50</td>\n",
       "      <td>2034.75</td>\n",
       "      <td>2040.50</td>\n",
       "      <td>34337</td>\n",
       "      <td>70002505.75</td>\n",
       "      <td>5587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-04 03:26:50.833</th>\n",
       "      <td>2040.50</td>\n",
       "      <td>2041.75</td>\n",
       "      <td>2025.75</td>\n",
       "      <td>2031.25</td>\n",
       "      <td>34443</td>\n",
       "      <td>70003995.50</td>\n",
       "      <td>8520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-04 06:17:16.453</th>\n",
       "      <td>2031.25</td>\n",
       "      <td>2032.75</td>\n",
       "      <td>2016.00</td>\n",
       "      <td>2016.00</td>\n",
       "      <td>34654</td>\n",
       "      <td>70077289.00</td>\n",
       "      <td>9943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-04 08:07:12.320</th>\n",
       "      <td>2016.25</td>\n",
       "      <td>2019.25</td>\n",
       "      <td>2007.50</td>\n",
       "      <td>2007.75</td>\n",
       "      <td>34800</td>\n",
       "      <td>70063062.25</td>\n",
       "      <td>7853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-04 08:47:15.283</th>\n",
       "      <td>2007.75</td>\n",
       "      <td>2007.75</td>\n",
       "      <td>2001.00</td>\n",
       "      <td>2005.25</td>\n",
       "      <td>34939</td>\n",
       "      <td>70026656.00</td>\n",
       "      <td>7407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-30 20:00:03.168</th>\n",
       "      <td>2090.50</td>\n",
       "      <td>2090.75</td>\n",
       "      <td>2087.25</td>\n",
       "      <td>2089.00</td>\n",
       "      <td>33527</td>\n",
       "      <td>70036244.50</td>\n",
       "      <td>1495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-30 20:00:54.844</th>\n",
       "      <td>2089.00</td>\n",
       "      <td>2089.25</td>\n",
       "      <td>2087.25</td>\n",
       "      <td>2087.75</td>\n",
       "      <td>33593</td>\n",
       "      <td>70148391.25</td>\n",
       "      <td>1935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-30 20:05:54.542</th>\n",
       "      <td>2087.50</td>\n",
       "      <td>2087.75</td>\n",
       "      <td>2086.25</td>\n",
       "      <td>2087.00</td>\n",
       "      <td>33725</td>\n",
       "      <td>70377246.25</td>\n",
       "      <td>2538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-30 20:13:58.349</th>\n",
       "      <td>2087.00</td>\n",
       "      <td>2089.25</td>\n",
       "      <td>2086.25</td>\n",
       "      <td>2088.50</td>\n",
       "      <td>33544</td>\n",
       "      <td>70033735.00</td>\n",
       "      <td>2612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-30 22:10:16.308</th>\n",
       "      <td>2088.75</td>\n",
       "      <td>2088.75</td>\n",
       "      <td>2085.50</td>\n",
       "      <td>2086.50</td>\n",
       "      <td>33532</td>\n",
       "      <td>70001796.00</td>\n",
       "      <td>3220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6556 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            open     high      low    close  cum_vol  \\\n",
       "date_time                                                              \n",
       "2016-01-04 01:17:36.863  2036.50  2043.50  2034.75  2040.50    34337   \n",
       "2016-01-04 03:26:50.833  2040.50  2041.75  2025.75  2031.25    34443   \n",
       "2016-01-04 06:17:16.453  2031.25  2032.75  2016.00  2016.00    34654   \n",
       "2016-01-04 08:07:12.320  2016.25  2019.25  2007.50  2007.75    34800   \n",
       "2016-01-04 08:47:15.283  2007.75  2007.75  2001.00  2005.25    34939   \n",
       "...                          ...      ...      ...      ...      ...   \n",
       "2016-06-30 20:00:03.168  2090.50  2090.75  2087.25  2089.00    33527   \n",
       "2016-06-30 20:00:54.844  2089.00  2089.25  2087.25  2087.75    33593   \n",
       "2016-06-30 20:05:54.542  2087.50  2087.75  2086.25  2087.00    33725   \n",
       "2016-06-30 20:13:58.349  2087.00  2089.25  2086.25  2088.50    33544   \n",
       "2016-06-30 22:10:16.308  2088.75  2088.75  2085.50  2086.50    33532   \n",
       "\n",
       "                          cum_dollar  cum_ticks  \n",
       "date_time                                        \n",
       "2016-01-04 01:17:36.863  70002505.75       5587  \n",
       "2016-01-04 03:26:50.833  70003995.50       8520  \n",
       "2016-01-04 06:17:16.453  70077289.00       9943  \n",
       "2016-01-04 08:07:12.320  70063062.25       7853  \n",
       "2016-01-04 08:47:15.283  70026656.00       7407  \n",
       "...                              ...        ...  \n",
       "2016-06-30 20:00:03.168  70036244.50       1495  \n",
       "2016-06-30 20:00:54.844  70148391.25       1935  \n",
       "2016-06-30 20:05:54.542  70377246.25       2538  \n",
       "2016-06-30 20:13:58.349  70033735.00       2612  \n",
       "2016-06-30 22:10:16.308  70001796.00       3220  \n",
       "\n",
       "[6556 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('dollar_bars.csv', nrows=40000)\n",
    "data.index = pd.to_datetime(data['date_time'])\n",
    "data = data.drop('date_time', axis=1)\n",
    "data = data.loc['2016-01-01':'2016-06-30']\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make meta-labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate RSI and Bollinger bands for side-preidcition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute RSI\n",
    "def relative_strength_index(df, n):\n",
    "        \"\"\"Calculate Relative Strength Index(RSI) for given data.\n",
    "        https://github.com/Crypto-toolbox/pandas-technical-indicators/blob/master/technical_indicators.py\n",
    "        \n",
    "        :param df: pandas.DataFrame\n",
    "        :param n: \n",
    "        :return: pandas.DataFrame\n",
    "        \"\"\"\n",
    "        i = 0\n",
    "        UpI = [0]\n",
    "        DoI = [0]\n",
    "        while i + 1 <= df.index[-1]:\n",
    "            UpMove = df.loc[i + 1, 'high'] - df.loc[i, 'high']\n",
    "            DoMove = df.loc[i, 'low'] - df.loc[i + 1, 'low']\n",
    "            if UpMove > DoMove and UpMove > 0:\n",
    "                UpD = UpMove\n",
    "            else:\n",
    "                UpD = 0\n",
    "            UpI.append(UpD)\n",
    "            if DoMove > UpMove and DoMove > 0:\n",
    "                DoD = DoMove\n",
    "            else:\n",
    "                DoD = 0\n",
    "            DoI.append(DoD)\n",
    "            i = i + 1\n",
    "        UpI = pd.Series(UpI)\n",
    "        DoI = pd.Series(DoI)\n",
    "        PosDI = pd.Series(UpI.ewm(span=n, min_periods=n).mean())\n",
    "        NegDI = pd.Series(DoI.ewm(span=n, min_periods=n).mean())\n",
    "        RSI = pd.Series(round(PosDI * 100. / (PosDI + NegDI)), name='RSI_' + str(n))\n",
    "        # df = df.join(RSI)\n",
    "        return RSI\n",
    "\n",
    "def get_rsi(data, window=14):\n",
    "    df = data.copy(deep=True).reset_index()\n",
    "    rsi = relative_strength_index(df, window)\n",
    "    rsi_df = pd.Series(data=rsi.values, index=data.index)\n",
    "    return rsi_df\n",
    "\n",
    "\n",
    "def bbands(close_prices, window, no_of_stdev):\n",
    "    rolling_mean = close_prices.ewm(span=window).mean()\n",
    "    rolling_std = close_prices.ewm(span=window).std()\n",
    "\n",
    "    upper_band = rolling_mean + (rolling_std * no_of_stdev)\n",
    "    lower_band = rolling_mean - (rolling_std * no_of_stdev)\n",
    "\n",
    "    return rolling_mean, upper_band, lower_band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>cum_vol</th>\n",
       "      <th>cum_dollar</th>\n",
       "      <th>cum_ticks</th>\n",
       "      <th>avg</th>\n",
       "      <th>upper</th>\n",
       "      <th>lower</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-06-06 19:55:54.770</th>\n",
       "      <td>2109.75</td>\n",
       "      <td>2109.75</td>\n",
       "      <td>2107.75</td>\n",
       "      <td>2108.75</td>\n",
       "      <td>33385</td>\n",
       "      <td>70394214.00</td>\n",
       "      <td>2749</td>\n",
       "      <td>2103.598324</td>\n",
       "      <td>2112.991362</td>\n",
       "      <td>2094.205286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-02 13:38:48.661</th>\n",
       "      <td>2090.75</td>\n",
       "      <td>2093.00</td>\n",
       "      <td>2090.25</td>\n",
       "      <td>2092.50</td>\n",
       "      <td>33468</td>\n",
       "      <td>70002268.75</td>\n",
       "      <td>3664</td>\n",
       "      <td>2093.505030</td>\n",
       "      <td>2098.691578</td>\n",
       "      <td>2088.318482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-29 13:47:47.706</th>\n",
       "      <td>2063.75</td>\n",
       "      <td>2065.75</td>\n",
       "      <td>2061.00</td>\n",
       "      <td>2062.00</td>\n",
       "      <td>33989</td>\n",
       "      <td>70115080.75</td>\n",
       "      <td>4038</td>\n",
       "      <td>2073.318252</td>\n",
       "      <td>2086.512625</td>\n",
       "      <td>2060.123878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-25 18:10:00.893</th>\n",
       "      <td>1889.50</td>\n",
       "      <td>1895.00</td>\n",
       "      <td>1888.00</td>\n",
       "      <td>1894.00</td>\n",
       "      <td>37005</td>\n",
       "      <td>70000155.00</td>\n",
       "      <td>5526</td>\n",
       "      <td>1890.166744</td>\n",
       "      <td>1900.892090</td>\n",
       "      <td>1879.441397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-02-24 20:23:40.438</th>\n",
       "      <td>1926.75</td>\n",
       "      <td>1928.00</td>\n",
       "      <td>1925.25</td>\n",
       "      <td>1925.75</td>\n",
       "      <td>36331</td>\n",
       "      <td>70000420.00</td>\n",
       "      <td>4198</td>\n",
       "      <td>1909.042127</td>\n",
       "      <td>1927.300922</td>\n",
       "      <td>1890.783331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-02-08 14:41:13.169</th>\n",
       "      <td>1842.00</td>\n",
       "      <td>1844.75</td>\n",
       "      <td>1841.00</td>\n",
       "      <td>1844.75</td>\n",
       "      <td>38020</td>\n",
       "      <td>70054715.25</td>\n",
       "      <td>5135</td>\n",
       "      <td>1868.609889</td>\n",
       "      <td>1895.789249</td>\n",
       "      <td>1841.430529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-28 12:07:52.417</th>\n",
       "      <td>1878.25</td>\n",
       "      <td>1878.50</td>\n",
       "      <td>1872.00</td>\n",
       "      <td>1874.00</td>\n",
       "      <td>37346</td>\n",
       "      <td>70035667.50</td>\n",
       "      <td>7917</td>\n",
       "      <td>1883.486716</td>\n",
       "      <td>1899.585584</td>\n",
       "      <td>1867.387847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-02-11 16:24:08.067</th>\n",
       "      <td>1814.75</td>\n",
       "      <td>1818.75</td>\n",
       "      <td>1812.25</td>\n",
       "      <td>1812.50</td>\n",
       "      <td>38549</td>\n",
       "      <td>70005751.25</td>\n",
       "      <td>5426</td>\n",
       "      <td>1827.744991</td>\n",
       "      <td>1852.732962</td>\n",
       "      <td>1802.757021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-05-20 00:37:06.745</th>\n",
       "      <td>2038.25</td>\n",
       "      <td>2042.00</td>\n",
       "      <td>2037.25</td>\n",
       "      <td>2042.00</td>\n",
       "      <td>34343</td>\n",
       "      <td>70026738.75</td>\n",
       "      <td>4510</td>\n",
       "      <td>2033.637470</td>\n",
       "      <td>2042.817151</td>\n",
       "      <td>2024.457790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-05-04 15:22:31.659</th>\n",
       "      <td>2045.50</td>\n",
       "      <td>2046.00</td>\n",
       "      <td>2042.00</td>\n",
       "      <td>2042.75</td>\n",
       "      <td>34267</td>\n",
       "      <td>70039705.25</td>\n",
       "      <td>4328</td>\n",
       "      <td>2050.794783</td>\n",
       "      <td>2060.959481</td>\n",
       "      <td>2040.630086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            open     high      low    close  cum_vol  \\\n",
       "date_time                                                              \n",
       "2016-06-06 19:55:54.770  2109.75  2109.75  2107.75  2108.75    33385   \n",
       "2016-06-02 13:38:48.661  2090.75  2093.00  2090.25  2092.50    33468   \n",
       "2016-04-29 13:47:47.706  2063.75  2065.75  2061.00  2062.00    33989   \n",
       "2016-01-25 18:10:00.893  1889.50  1895.00  1888.00  1894.00    37005   \n",
       "2016-02-24 20:23:40.438  1926.75  1928.00  1925.25  1925.75    36331   \n",
       "2016-02-08 14:41:13.169  1842.00  1844.75  1841.00  1844.75    38020   \n",
       "2016-01-28 12:07:52.417  1878.25  1878.50  1872.00  1874.00    37346   \n",
       "2016-02-11 16:24:08.067  1814.75  1818.75  1812.25  1812.50    38549   \n",
       "2016-05-20 00:37:06.745  2038.25  2042.00  2037.25  2042.00    34343   \n",
       "2016-05-04 15:22:31.659  2045.50  2046.00  2042.00  2042.75    34267   \n",
       "\n",
       "                          cum_dollar  cum_ticks          avg        upper  \\\n",
       "date_time                                                                   \n",
       "2016-06-06 19:55:54.770  70394214.00       2749  2103.598324  2112.991362   \n",
       "2016-06-02 13:38:48.661  70002268.75       3664  2093.505030  2098.691578   \n",
       "2016-04-29 13:47:47.706  70115080.75       4038  2073.318252  2086.512625   \n",
       "2016-01-25 18:10:00.893  70000155.00       5526  1890.166744  1900.892090   \n",
       "2016-02-24 20:23:40.438  70000420.00       4198  1909.042127  1927.300922   \n",
       "2016-02-08 14:41:13.169  70054715.25       5135  1868.609889  1895.789249   \n",
       "2016-01-28 12:07:52.417  70035667.50       7917  1883.486716  1899.585584   \n",
       "2016-02-11 16:24:08.067  70005751.25       5426  1827.744991  1852.732962   \n",
       "2016-05-20 00:37:06.745  70026738.75       4510  2033.637470  2042.817151   \n",
       "2016-05-04 15:22:31.659  70039705.25       4328  2050.794783  2060.959481   \n",
       "\n",
       "                               lower  \n",
       "date_time                             \n",
       "2016-06-06 19:55:54.770  2094.205286  \n",
       "2016-06-02 13:38:48.661  2088.318482  \n",
       "2016-04-29 13:47:47.706  2060.123878  \n",
       "2016-01-25 18:10:00.893  1879.441397  \n",
       "2016-02-24 20:23:40.438  1890.783331  \n",
       "2016-02-08 14:41:13.169  1841.430529  \n",
       "2016-01-28 12:07:52.417  1867.387847  \n",
       "2016-02-11 16:24:08.067  1802.757021  \n",
       "2016-05-20 00:37:06.745  2024.457790  \n",
       "2016-05-04 15:22:31.659  2040.630086  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute bands\n",
    "window = 50\n",
    "data['avg'], data['upper'], data['lower'] = bbands(data['close'], window, no_of_stdev=1.5)\n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute RSI\n",
    "rsi_df = get_rsi(data, window=14)\n",
    "data['rsi'] = pd.Series(data=rsi_df.values, index=data.index)\n",
    "\n",
    "# Drop the NaN values from our data set\n",
    "data.dropna(axis=0, how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1.0    349\n",
      "-1.0    287\n",
      "Name: side, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Compute sides\n",
    "data['side'] = np.nan \n",
    "\n",
    "long_signals = (data['close'] <= data['lower']) \n",
    "short_signals = (data['close'] >= data['upper']) \n",
    "\n",
    "data.loc[long_signals, 'side'] = 1\n",
    "data.loc[short_signals, 'side'] = -1\n",
    "\n",
    "print(data.side.value_counts())\n",
    "\n",
    "# Remove Look ahead bias by lagging the signal\n",
    "data['side'] = data['side'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1.0    349\n",
      "-1.0    287\n",
      "Name: side, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Save the raw data\n",
    "raw_data = data.copy(deep=True)\n",
    "\n",
    "# Drop the NaN values from our data set\n",
    "data.dropna(axis=0, how='any', inplace=True)\n",
    "print(data.side.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-13 12:52:15.124852 100.0% apply_pt_sl_on_t1 done after 0.0 minutes. Remaining 0.0 minutes.\n"
     ]
    }
   ],
   "source": [
    "# Compute daily volatility\n",
    "daily_vol = ml.util.get_daily_vol(close=data['close'], lookback=50)\n",
    "\n",
    "# Apply Symmetric CUSUM Filter and get timestamps for events\n",
    "# Note: Only the CUSUM filter needs a point estimate for volatility\n",
    "cusum_events = ml.filters.cusum_filter(data['close'], threshold=daily_vol.mean() * 0.1)\n",
    "\n",
    "# Compute vertical barrier\n",
    "vertical_barriers = ml.labeling.add_vertical_barrier(t_events=cusum_events, close=data['close'], num_days=1)\n",
    "\n",
    "pt_sl = [0, 2]\n",
    "min_ret = 0.0005\n",
    "\n",
    "triple_barrier_events = ml.labeling.get_events(close=data['close'],\n",
    "                                               t_events=cusum_events,\n",
    "                                               pt_sl=pt_sl,\n",
    "                                               target=daily_vol,\n",
    "                                               min_ret=min_ret,\n",
    "                                               num_threads=2,\n",
    "                                               vertical_barrier_times=vertical_barriers,\n",
    "                                               side_prediction=data['side'])\n",
    "labels = ml.labeling.get_bins(triple_barrier_events, data['close'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log Returns\n",
    "raw_data['log_ret'] = np.log(raw_data['close']).diff()\n",
    "\n",
    "# Momentum\n",
    "raw_data['mom1'] = raw_data['close'].pct_change(periods=1)\n",
    "raw_data['mom2'] = raw_data['close'].pct_change(periods=2)\n",
    "raw_data['mom3'] = raw_data['close'].pct_change(periods=3)\n",
    "raw_data['mom4'] = raw_data['close'].pct_change(periods=4)\n",
    "raw_data['mom5'] = raw_data['close'].pct_change(periods=5)\n",
    "\n",
    "# Volatility\n",
    "window_stdev = 50\n",
    "raw_data['volatility'] = raw_data['log_ret'].rolling(window=window_stdev, min_periods=window_stdev, center=False).std()\n",
    "\n",
    "# Serial Correlation (Takes about 4 minutes)\n",
    "window_autocorr = 50\n",
    "\n",
    "raw_data['autocorr_1'] = raw_data['log_ret'].rolling(window=window_autocorr, min_periods=window_autocorr, center=False).apply(lambda x: x.autocorr(lag=1), raw=False)\n",
    "raw_data['autocorr_2'] = raw_data['log_ret'].rolling(window=window_autocorr, min_periods=window_autocorr, center=False).apply(lambda x: x.autocorr(lag=2), raw=False)\n",
    "raw_data['autocorr_3'] = raw_data['log_ret'].rolling(window=window_autocorr, min_periods=window_autocorr, center=False).apply(lambda x: x.autocorr(lag=3), raw=False)\n",
    "raw_data['autocorr_4'] = raw_data['log_ret'].rolling(window=window_autocorr, min_periods=window_autocorr, center=False).apply(lambda x: x.autocorr(lag=4), raw=False)\n",
    "raw_data['autocorr_5'] = raw_data['log_ret'].rolling(window=window_autocorr, min_periods=window_autocorr, center=False).apply(lambda x: x.autocorr(lag=5), raw=False)\n",
    "\n",
    "# Get the various log -t returns\n",
    "raw_data['log_t1'] = raw_data['log_ret'].shift(1)\n",
    "raw_data['log_t2'] = raw_data['log_ret'].shift(2)\n",
    "raw_data['log_t3'] = raw_data['log_ret'].shift(3)\n",
    "raw_data['log_t4'] = raw_data['log_ret'].shift(4)\n",
    "raw_data['log_t5'] = raw_data['log_ret'].shift(5)\n",
    "\n",
    "# Add fast and slow moving averages\n",
    "fast_window = 7\n",
    "slow_window = 15\n",
    "\n",
    "raw_data['fast_mavg'] = raw_data['close'].rolling(window=fast_window, min_periods=fast_window, center=False).mean()\n",
    "raw_data['slow_mavg'] = raw_data['close'].rolling(window=slow_window, min_periods=slow_window, center=False).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Trending signals\n",
    "raw_data['sma'] = np.nan\n",
    "\n",
    "long_signals = raw_data['fast_mavg'] >= raw_data['slow_mavg']\n",
    "short_signals = raw_data['fast_mavg'] < raw_data['slow_mavg']\n",
    "raw_data.loc[long_signals, 'sma'] = 1\n",
    "raw_data.loc[short_signals, 'sma'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re compute sides\n",
    "raw_data['side'] = np.nan\n",
    "\n",
    "long_signals = raw_data['close'] <= raw_data['lower'] \n",
    "short_signals = raw_data['close'] >= raw_data['upper'] \n",
    "\n",
    "raw_data.loc[long_signals, 'side'] = 1\n",
    "raw_data.loc[short_signals, 'side'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>cum_vol</th>\n",
       "      <th>cum_dollar</th>\n",
       "      <th>cum_ticks</th>\n",
       "      <th>avg</th>\n",
       "      <th>upper</th>\n",
       "      <th>lower</th>\n",
       "      <th>...</th>\n",
       "      <th>autocorr_4</th>\n",
       "      <th>autocorr_5</th>\n",
       "      <th>log_t1</th>\n",
       "      <th>log_t2</th>\n",
       "      <th>log_t3</th>\n",
       "      <th>log_t4</th>\n",
       "      <th>log_t5</th>\n",
       "      <th>fast_mavg</th>\n",
       "      <th>slow_mavg</th>\n",
       "      <th>sma</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-04 14:40:05.559</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-04 14:43:34.220</th>\n",
       "      <td>1997.75</td>\n",
       "      <td>1999.25</td>\n",
       "      <td>1995.75</td>\n",
       "      <td>1996.50</td>\n",
       "      <td>35065.0</td>\n",
       "      <td>70034780.25</td>\n",
       "      <td>4243.0</td>\n",
       "      <td>2005.024831</td>\n",
       "      <td>2023.794262</td>\n",
       "      <td>1986.255400</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-04 14:48:09.087</th>\n",
       "      <td>1996.50</td>\n",
       "      <td>1997.00</td>\n",
       "      <td>1991.50</td>\n",
       "      <td>1993.00</td>\n",
       "      <td>35200.0</td>\n",
       "      <td>70188370.25</td>\n",
       "      <td>4463.0</td>\n",
       "      <td>2003.979777</td>\n",
       "      <td>2022.629063</td>\n",
       "      <td>1985.330492</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-04 14:52:18.754</th>\n",
       "      <td>1993.00</td>\n",
       "      <td>1993.25</td>\n",
       "      <td>1990.50</td>\n",
       "      <td>1992.75</td>\n",
       "      <td>35144.0</td>\n",
       "      <td>70002843.25</td>\n",
       "      <td>4464.0</td>\n",
       "      <td>2003.048247</td>\n",
       "      <td>2021.504820</td>\n",
       "      <td>1984.591674</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.001755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-04 14:57:30.085</th>\n",
       "      <td>1992.75</td>\n",
       "      <td>1999.00</td>\n",
       "      <td>1992.75</td>\n",
       "      <td>1998.00</td>\n",
       "      <td>35221.0</td>\n",
       "      <td>70295761.75</td>\n",
       "      <td>4348.0</td>\n",
       "      <td>2002.647033</td>\n",
       "      <td>2020.447477</td>\n",
       "      <td>1984.846589</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000125</td>\n",
       "      <td>-0.001755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            open     high      low    close  cum_vol  \\\n",
       "date_time                                                              \n",
       "2016-01-04 14:40:05.559      NaN      NaN      NaN      NaN      NaN   \n",
       "2016-01-04 14:43:34.220  1997.75  1999.25  1995.75  1996.50  35065.0   \n",
       "2016-01-04 14:48:09.087  1996.50  1997.00  1991.50  1993.00  35200.0   \n",
       "2016-01-04 14:52:18.754  1993.00  1993.25  1990.50  1992.75  35144.0   \n",
       "2016-01-04 14:57:30.085  1992.75  1999.00  1992.75  1998.00  35221.0   \n",
       "\n",
       "                          cum_dollar  cum_ticks          avg        upper  \\\n",
       "date_time                                                                   \n",
       "2016-01-04 14:40:05.559          NaN        NaN          NaN          NaN   \n",
       "2016-01-04 14:43:34.220  70034780.25     4243.0  2005.024831  2023.794262   \n",
       "2016-01-04 14:48:09.087  70188370.25     4463.0  2003.979777  2022.629063   \n",
       "2016-01-04 14:52:18.754  70002843.25     4464.0  2003.048247  2021.504820   \n",
       "2016-01-04 14:57:30.085  70295761.75     4348.0  2002.647033  2020.447477   \n",
       "\n",
       "                               lower  ...  autocorr_4  autocorr_5    log_t1  \\\n",
       "date_time                             ...                                     \n",
       "2016-01-04 14:40:05.559          NaN  ...         NaN         NaN       NaN   \n",
       "2016-01-04 14:43:34.220  1986.255400  ...         NaN         NaN       NaN   \n",
       "2016-01-04 14:48:09.087  1985.330492  ...         NaN         NaN       NaN   \n",
       "2016-01-04 14:52:18.754  1984.591674  ...         NaN         NaN -0.001755   \n",
       "2016-01-04 14:57:30.085  1984.846589  ...         NaN         NaN -0.000125   \n",
       "\n",
       "                           log_t2  log_t3  log_t4  log_t5  fast_mavg  \\\n",
       "date_time                                                              \n",
       "2016-01-04 14:40:05.559       NaN     NaN     NaN     NaN        NaN   \n",
       "2016-01-04 14:43:34.220       NaN     NaN     NaN     NaN        NaN   \n",
       "2016-01-04 14:48:09.087       NaN     NaN     NaN     NaN        NaN   \n",
       "2016-01-04 14:52:18.754       NaN     NaN     NaN     NaN        NaN   \n",
       "2016-01-04 14:57:30.085 -0.001755     NaN     NaN     NaN        NaN   \n",
       "\n",
       "                         slow_mavg  sma  \n",
       "date_time                                \n",
       "2016-01-04 14:40:05.559        NaN  NaN  \n",
       "2016-01-04 14:43:34.220        NaN  NaN  \n",
       "2016-01-04 14:48:09.087        NaN  NaN  \n",
       "2016-01-04 14:52:18.754        NaN  NaN  \n",
       "2016-01-04 14:57:30.085        NaN  NaN  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove look ahead bias\n",
    "raw_data = raw_data.shift(1)\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get features at event dates\n",
    "X = raw_data.loc[labels.index, :]\n",
    "\n",
    "# Drop unwanted columns\n",
    "X.drop(['avg', 'upper', 'lower', 'open', 'high', 'low', 'close', 'cum_vol', 'cum_dollar', 'cum_ticks','fast_mavg', 'slow_mavg',], axis=1, inplace=True)\n",
    "\n",
    "y = labels['bin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training, validation and test sets\n",
    "X_training_test = X\n",
    "y_training_test = y\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_training_test, y_training_test, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    185\n",
       "0    106\n",
       "Name: bin, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.concat([y_train, X_train], axis=1, join='inner')\n",
    "train_df = train_df.dropna()\n",
    "train_df['bin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training data\n",
    "y_train = train_df['bin']\n",
    "X_train= train_df.loc[:, train_df.columns != 'bin']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SequentiallyBootstrappedBaggingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we are making classifiers. If your task is regression type, please check _SequentiallyBootstrappedBaggingRegressor_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlfinlab.ensemble import SequentiallyBootstrappedBaggingClassifier\n",
    "from mlfinlab.sampling.concurrent import get_av_uniqueness_from_triple_barrier\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-13 12:52:27.364022 100.0% num_concurrent_events done after 0.0 minutes. Remaining 0.0 minutes.\n",
      "2020-04-13 12:52:27.463654 100.0% _get_average_uniqueness done after 0.0 minutes. Remaining 0.0 minutes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.21987054594884525"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "av_unique = get_av_uniqueness_from_triple_barrier(triple_barrier_events, raw_data.close, num_threads=3)\n",
    "avgU = av_unique['tW'].mean()\n",
    "avgU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _BaggingClassifier_ with _DecisionTreeClassifier_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* _max_samples_: the average uniqueness(_avgU_) between samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_trees = DecisionTreeClassifier(criterion='entropy', max_features='auto', class_weight='balanced')\n",
    "bagging_ensemble = BaggingClassifier(base_estimator=base_trees, n_estimators=1000, max_samples=avgU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf = SequentiallyBootstrappedBaggingClassifier(base_estimator=bagging_ensemble,\n",
    "                                                samples_info_sets=triple_barrier_events.loc[X.index, :],\n",
    "                                                price_bars=data.close,\n",
    "                                                max_samples=avgU\n",
    "                                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentiallyBootstrappedBaggingClassifier(base_estimator=BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight='balanced',\n",
       "                                                                                                                 criterion='entropy',\n",
       "                                                                                                                 max_depth=None,\n",
       "                                                                                                                 max_features='auto',\n",
       "                                                                                                                 max_leaf_nodes=None,\n",
       "                                                                                                                 min_impurity_decrease=0.0,\n",
       "                                                                                                                 min_impurity_split=None,\n",
       "                                                                                                                 min_samples_leaf=1,\n",
       "                                                                                                                 min_samples_split=2,\n",
       "                                                                                                                 min_weight_fraction_leaf=0.0,\n",
       "                                                                                                                 presort=False,\n",
       "                                                                                                                 random...\n",
       "2016-06-24 05:07:07.901 2016-06-26 23:10:23.823000064  0.019140   1.0   0   2\n",
       "2016-06-24 06:02:15.065 2016-06-26 23:10:23.823000064  0.019954   1.0   0   2\n",
       "2016-06-26 23:10:23.823 2016-06-28 19:04:04.158000128  0.019820   1.0   0   2\n",
       "2016-06-27 01:30:01.533 2016-06-28 19:04:04.158000128  0.019446   1.0   0   2\n",
       "2016-06-27 03:30:00.056 2016-06-28 19:04:04.158000128  0.019288   1.0   0   2\n",
       "\n",
       "[364 rows x 5 columns],\n",
       "                                          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train.values.ravel())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BaggingClassifier on RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* _max_samples_: the average uniqueness(_avgU_) between samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_1_tree = RandomForestClassifier(n_estimators=1, criterion='entropy', bootstrap=False, class_weight='balanced_subsample')\n",
    "clf2 = SequentiallyBootstrappedBaggingClassifier(base_estimator=rf_1_tree,\n",
    "                                                 samples_info_sets=triple_barrier_events.loc[X.index, :],\n",
    "                                                 price_bars=data.close,\n",
    "                                                 max_samples=avgU\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentiallyBootstrappedBaggingClassifier(base_estimator=RandomForestClassifier(bootstrap=False,\n",
       "                                                                                class_weight='balanced_subsample',\n",
       "                                                                                criterion='entropy',\n",
       "                                                                                max_depth=None,\n",
       "                                                                                max_features='auto',\n",
       "                                                                                max_leaf_nodes=None,\n",
       "                                                                                min_impurity_decrease=0.0,\n",
       "                                                                                min_impurity_split=None,\n",
       "                                                                                min_samples_leaf=1,\n",
       "                                                                                min_samples_split=2,\n",
       "                                                                                min_weight_fraction_leaf=0.0,\n",
       "                                                                                n_estimators=1,\n",
       "                                                                                n_jobs=None,...\n",
       "2016-06-24 05:07:07.901 2016-06-26 23:10:23.823000064  0.019140   1.0   0   2\n",
       "2016-06-24 06:02:15.065 2016-06-26 23:10:23.823000064  0.019954   1.0   0   2\n",
       "2016-06-26 23:10:23.823 2016-06-28 19:04:04.158000128  0.019820   1.0   0   2\n",
       "2016-06-27 01:30:01.533 2016-06-28 19:04:04.158000128  0.019446   1.0   0   2\n",
       "2016-06-27 03:30:00.056 2016-06-28 19:04:04.158000128  0.019288   1.0   0   2\n",
       "\n",
       "[364 rows x 5 columns],\n",
       "                                          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2.fit(X_train, y_train.values.ravel())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
